{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading dataset\n",
    "import pandas as pd\n",
    "money = pd.read_csv('M2SLMoneyStock.csv')\n",
    "spending = pd.read_csv('PCEPersonalSpending.csv')\n",
    "df =pd.merge(money, spending, on='Date', how='outer')\n",
    "#df2 = pd.merge(passengers, restaurant, on='Date', how='outer')\n",
    "# set index to Date\n",
    "df = df.set_index('Date')\n",
    "# convert index into datetime format\n",
    "df.index = pd.DatetimeIndex(df.index).to_period('m')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e39b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking stationarity, \n",
    "# Cointegration is a statistical method used to test the correlation between two or more non-stationary time series \n",
    "# in the long run or for a specified period\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "#since the test works for only 12 variables, I have randomly dropped\n",
    "#in the next iteration, I would drop another and check the eigenvalues\n",
    "\n",
    "#coint_johansen(endog, det_order, k_ar_diff); k_ar_diff Number of lagged differences in the model.\n",
    "# det_order: determintation order; -1 no-determinstic terms: the order of time polynomial in the null-hypothesis\n",
    "data= df.dropna()\n",
    "# Eigenvalues of  coefficient matrix\n",
    "result=coint_johansen(data,-1,1).eig\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c1f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d01ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and validation sets: 90% for training, 10% for validation\n",
    "data= df.dropna()\n",
    "train = data[:int(0.9*(len(df)))]\n",
    "test = data[int(0.9*(len(df))):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8eb81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using vector autogregression model \n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "# a pth-order VAR refers to a VAR model which includes lags for the last p time periods\n",
    "# fit(maxlags): Maximum number of lags to check for order selection,\n",
    "# defaults to 12 * (nobs/100.)**(1./4)\n",
    "# we set order = 5 \n",
    "model = VAR(endog=train, freq='M')\n",
    "fitted_var = model.fit(5)# fitted_var.summary(): to access model output\n",
    "\n",
    "\n",
    "# make predictions and evaluate the model on validation set\n",
    "# VARResults.forecast: Produce linear minimum MSE forecasts for desired number of steps ahead, using prior values y\n",
    "lagged_Vals = train.values[-10:]# The VAR .forecast() requires passing in a lag order number of previous observations.\n",
    "predictions = fitted_var.forecast(y=lagged_Vals, steps=len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the predictions are made as an array, where each list represents the predictions of a row in the dataset.\n",
    "# we need first to convert the array into  a dataframe\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "# locate the predictions in a new dataframe with the same col names: without 'CO(GT)'\n",
    "cols =df.columns\n",
    "idx = test.index\n",
    "pred = pd.DataFrame(index=idx,columns=[cols])\n",
    "for j in range(0,2):\n",
    "    for i in range(0, len(predictions)):\n",
    "        pred.iloc[i][j] = predictions[i][j]\n",
    "\n",
    "#calculate MAPE for all cols\n",
    "for col in cols:\n",
    "    print('MAPE value for', col, 'is : ', mean_absolute_percentage_error(pred[col], test[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c20cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot cols against predictions\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.subplots(figsize=(8,5))\n",
    "test2 = test.to_timestamp(freq='d')\n",
    "\n",
    "df_forecast=pd.DataFrame(data=pred, index=idx, columns=cols)\n",
    "plt.plot(test2['Money'],color=\"green\", label ='Money')\n",
    "plt.plot(pred['Money'], color=\"blue\", label ='Money forecasts')\n",
    "plt.plot(test2['Spending'],color=\"red\", label ='Spending')\n",
    "plt.plot(pred['Spending'], color=\"black\", label ='Spending forecasts')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "# since each variable is a linear function of past lags of itself and past lags of the other variables, we get fitted lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LSTM;\n",
    "# first we need to scale input and output of LSTM using standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled =scaler.fit_transform(train)\n",
    "x_train_scaled.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using money variable as input time series\n",
    "scaler2= StandardScaler()\n",
    "y_train_scaled =scaler2.fit_transform(train[['Money']])\n",
    "y_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lag= 5 we need to create the sequences of the input array manually;reshaping input data\n",
    "import numpy as np\n",
    "x_train=[]\n",
    "y_train = []\n",
    "for i in range(5, 226):\n",
    "    x_train.append(x_train_scaled[i-5:i])\n",
    "    y_train.append(y_train_scaled[i][0])\n",
    "x_train= np.array(x_train)    \n",
    "y_train = np.array(y_train) \n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LSTM model \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import  Dropout, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(5,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16544270",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "history = model.fit(x_train, y_train, epochs=200, batch_size= 32, shuffle=False, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f649a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the last 5 of train set to the test set: to be used for forecasting, since we use 5 lags \n",
    "train_last_5= train[-5:]\n",
    "extended_test= pd.concat((train_last_5, test), axis=0)\n",
    "# rescaling test data\n",
    "scaled_test= scaler.fit_transform(extended_test)\n",
    "scaled_test.shape\n",
    "\n",
    "# rescaling y \n",
    "y_test_scaled = scaler2.fit_transform(extended_test[['Money']])\n",
    "y_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping input data for testing the model\n",
    "x_test=[]\n",
    "for i in range(5, 31):\n",
    "    x_test.append(scaled_test[i-5:i])    \n",
    "x_test= np.array(x_test)    \n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2490c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecasting on test data\n",
    "y_test=model.predict(x_test)\n",
    "# inverse scaling of money forecasts\n",
    "y= scaler2.inverse_transform(y_test)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd59e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting predictions against actual money values\n",
    "fig = plt.subplots(figsize=(10,6))\n",
    "test2 = test.to_timestamp(freq='d')\n",
    "df_forecast=pd.DataFrame(data=y, index=idx)\n",
    "plt.plot(test2['Money'],color=\"red\", label ='Money')\n",
    "plt.plot(df_forecast, color=\"blue\", label ='Money forecasts')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE between forecasts and actual money\n",
    "print('MAPE value for Money is:', mean_absolute_percentage_error(y, test['Money']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}