{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#markovify \n",
    "!pip install nltk \n",
    "!pip install markovify\n",
    "!pip install spacy\n",
    "#!pip install -m spacy download en\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c8a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import spacy\n",
    "#regular exprssion \n",
    "import re\n",
    "import markovify\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "#inspect Gutenberg corpus\n",
    "print(gutenberg.fileids())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd02d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the plays\n",
    "macbeth = gutenberg.raw('shakespeare-macbeth.txt')\n",
    "hamlet = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "caesar = gutenberg.raw('shakespeare-caesar.txt')\n",
    "\n",
    "#print the first 100 char of each play to take a look\n",
    "print('\\nmacbeth:\\n', hamlet[:250])\n",
    "print('\\ncaesar:\\n', caesar[:250])\n",
    "print('\\nhamlet:\\n', macbeth[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77741bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning; re.sub() replaces the occurences of a string by the second argument(repl)\n",
    "#The r means that the string is to be treated as a raw string, which means all escape codes will be ignored.e.g '\\n' will NOT be\n",
    "# treated as new line but as '\\' followed by 'n'.\n",
    "# '|' creates a regular expression that will match either A or B.\n",
    "# \\b Matches the empty string, but only at the beginning or end of a word\n",
    "# \\s Matches Unicode whitespace characters ..\n",
    "# \\d Matches any Unicode decimal digits\n",
    "# * Causes the resulting RE to match 0 or more repetitions of the preceding RE, e.g. ab* will match ‘a’, ‘ab’, or ‘a’ followed by any number of ‘b’s.\n",
    "# + Causes the resulting RE to match 1 or more repetitions of the preceding RE, e.g. ab+ will match ‘a’ followed by any non-zero number of ‘b’s; it will not match just ‘a’.\n",
    "# ? Causes the resulting RE to match 0 or 1 repetitions of the preceding RE, e.g. ab? will match either ‘a’ or ‘ab’.\n",
    "# \\ Either escapes special characters (permitting you to match characters like '*', '?', and so forth).\n",
    "# [] Used to indicate a set of characters. In a set: Characters can be listed individually, e.g. [amk] will match 'a', 'm', or 'k'.\n",
    "# OR Ranges of characters can be indicated by giving two characters and separating them by a '-'. e.g. [0-5][0-9] will match all the two-digits numbers from 00 to 59,\n",
    "# and [0-9A-Fa-f] will match any hexadecimal digit.\n",
    "# ^ Matches the start of the string \n",
    "# white space characters:  ' – Space. '\\t' – Horizontal tab.'\\v' – Vertical tab.'\\n' – Newline.'\\r' – Carriage return.'\\f' – Feed\n",
    "#text =' cvmm,-645e2wkk9875=[?=*!\\mmm ^^ --\\n \\f\\v'\n",
    "#text = re.sub(r'[m+ -- \\[*. \\??* \\d+ \\^ \\s]', '', text), >> cvewkk==\\\n",
    "def clean_txt(txt):\n",
    "    #text = re.sub(r'[m+ -- \\[*. \\??* \\d+ \\^ \\s]', '', txt)\n",
    "    text = re.sub(r'--', '', txt)\n",
    "    text = re.sub('[\\[].*?[\\]]', '', text)\n",
    "    text = re.sub(r'(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+ )\\b','', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove chapter indicators\n",
    "hamlet = re.sub(r'Chapter \\d+', '', hamlet)\n",
    "macbeth = re.sub(r'Chapter \\d+', '', macbeth)\n",
    "caesar = re.sub(r'Chapter \\d+', '', caesar)\n",
    "#cleaning the texts\n",
    "hamlet = clean_txt(hamlet)\n",
    "macbeth = clean_txt(macbeth)\n",
    "caesar= clean_txt(caesar)\n",
    "print(hamlet[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdeb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing the cleaned text \n",
    "# spacy.load() is used as a wrapper to read the pipline by means of language:'en' to construct language object\n",
    "lang_obj = spacy.load('en_core_web_sm')\n",
    "hamlet_obj = lang_obj(hamlet)\n",
    "macbeth_obj = lang_obj(macbeth)\n",
    "caesar_obj = lang_obj(caesar)\n",
    "print(hamlet_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a15d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the sentences in the documents, language object consists of 'word' elements, that's why hamlet_obj[:100] is longer than \n",
    "# hamlet_sents[:100]\n",
    "hamlet_sents = ' '.join([sent.text for sent in hamlet_obj.sents if len(sent.text) > 1])\n",
    "macbeth_sents = ' '.join([sent.text for sent in macbeth_obj.sents if len(sent.text) > 1])\n",
    "caesar_sents = ' '.join([sent.text for sent in caesar_obj.sents if len(sent.text) > 1])\n",
    "# combination of three novels \n",
    "HMC = hamlet_sents + macbeth_sents + caesar_sents\n",
    "print(len(HMC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16092e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create text generator using markovify\n",
    "# State size is a number of words the probability of a next word depends on.\n",
    "# for text generation: we will build Markov model using three of Shakespeares' Tragedies from the Project Gutenberg NLTK corpus.\n",
    "gen = markovify.Text(HMC, state_size=1)\n",
    "\n",
    "#generating short and long sentences  using make_sentance() and make_short_sentence()\n",
    "print('long sentences: \\n')\n",
    "for i in range(4):\n",
    "    print(gen.make_sentence())\n",
    "    \n",
    "print('\\n short sentences: \\n')    \n",
    "for i in range(4):\n",
    "    # of max 100 chars \n",
    "    print(gen.make_short_sentence(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to improve the text prediction we will use POSifiedText class: spaCy tagger to generate a Markov model that comply with\n",
    "# sentence structure better than a naive model.\n",
    "\n",
    "#in spacy library POS tagging is the process of marking a word in the text\n",
    "#to a particular part of speech based on both its context and definition.\n",
    "#In simple language, we can say that POS tagging is the process of identifying a word as nouns,\n",
    "#pronouns, verbs, adjectives, etc.\n",
    "\n",
    "class POSifiedText(markovify.Text):\n",
    "    def word_split(self, sentence):\n",
    "        return ['::'.join((word.orth_, word.pos_)) for word in lang_obj(sentence)] # add word tags(positions)\n",
    "    def word_join(self, words):\n",
    "        sentence = ' '.join(word.split('::')[0] for word in words)# re-build senetences for the model\n",
    "        return sentence\n",
    "generator_2 = POSifiedText(HMC, state_size=2)\n",
    "generator_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('short sentences: \\n')\n",
    "for i in range(4):\n",
    "    print(generator_2.make_short_sentence(max_chars=100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n long sentences: \\n')\n",
    "for i in range(4):\n",
    "     print(generator_2.make_sentence())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
