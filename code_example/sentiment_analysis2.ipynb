{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# three sentiments here:  negative(-1), neutral(0), and positive(+1).\n",
    "data = pd.read_csv(\"Twitter_Data.csv\")\n",
    "\n",
    "# rename 'category' column into 'label'\n",
    "data.rename(columns = {'category':'label'}, inplace = True)\n",
    "data.head(1)['clean_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a878b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the distribution of the labels\n",
    "data['label'].value_counts()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304440fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot label distribution\n",
    "import seaborn as sns\n",
    "ax=sns.countplot(data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from gensim.utils import simple_preprocess\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#stop words of the English dictionary\n",
    "stop_w = stopwords.words('English')\n",
    "#stop_words.extend(['from', 'subject', 're', 'edu', 'use','of', 'as', 'by', 'uc'])\n",
    "\n",
    "def process(text):\n",
    "   \n",
    "    # deacc=True removes punctuations\n",
    "    no_punc = gensim.utils.simple_preprocess(str(text), deacc=True)\n",
    "    return [word for word in no_punc if word not in stop_w] # for each doc in the text, remove stop words\n",
    "data['clean_text'] = data['clean_text'].apply(process)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a83308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66262f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import Counter\n",
    "# get individual words\n",
    "words = []\n",
    "for row in data['clean_text']: \n",
    "    words.extend(row)\n",
    " \n",
    "\n",
    "# Counter is a subclass for counting objects.\n",
    "# It is a collection where elements are stored as dictionary keys and their counts are stored as dictionary values\n",
    "word_freq = Counter(words)\n",
    "\n",
    "# plotting a Word Cloud \n",
    "word_cloud = WordCloud(\n",
    " background_color='white',\n",
    " max_words=2000,\n",
    " stopwords=stopwords\n",
    " ).generate_from_frequencies(word_freq)\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.imshow(word_cloud) # display as an image\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc09c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the words in the cloud seem neutral. It doesn’t give any idea about racist / sexist tweets.\n",
    "# let's take a look at the positive tweets\n",
    "positive_rows = [r for r in data['clean_text'][data['label']==1.0]]\n",
    "pos_words =[]\n",
    "for twt in positive_rows : \n",
    "    pos_words.extend(twt)\n",
    "#print(pos_words[:200])\n",
    "\n",
    "# positive word frequencies\n",
    "pos_freq = Counter(pos_words)\n",
    "\n",
    "# positive words cloud\n",
    "pos_cloud = WordCloud(\n",
    " background_color='white',\n",
    " max_words=2000,\n",
    " stopwords=stopwords\n",
    " ).generate_from_frequencies(pos_freq)\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.imshow(pos_cloud) # display as an image\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01872845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import Counter\n",
    "# get individual words for negative tweets\n",
    "neg_rows = [r for r in data['clean_text'][data['label']== -1.0]]\n",
    "neg_words =[]\n",
    "for twt in neg_rows : \n",
    "    neg_words.extend(twt)\n",
    "    \n",
    "# Counter is a subclass for counting objects.\n",
    "# It is a collection where elements are stored as dictionary keys and their counts are stored as dictionary values\n",
    "# negative word frequencies\n",
    "neg_freq = Counter(neg_words)\n",
    "\n",
    "# positive words cloud\n",
    "neg_cloud = WordCloud(\n",
    " background_color='black',\n",
    " max_words=2000,\n",
    " stopwords=stopwords\n",
    " ).generate_from_frequencies(neg_freq)\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.imshow(neg_cloud, interpolation='bilinear') # display as an image, we could use interpolation \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aaca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The bag-of-words model is a simplifying representation used in Natural language processing.\n",
    "#In this model, a text is represented as the bag of its words (independent features) ,disregarding grammar but keeping multiplicity.\n",
    "# We will use SciKit Learn’s CountVectorizer function which will convert a collection of \n",
    "# text documents into a matrix of token counts or feature table\n",
    "# we will use TfidfTransformer as a normalization method\n",
    "\n",
    "# drop rows with Nan values from the dataset\n",
    "data = data.dropna()\n",
    "#Split data into training and testing sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "# join clean_txt lists into strings to apply CountVectorizer, otherwise it gives an error\n",
    "\n",
    "x_train, x_test, y_train, y_test =  train_test_split(data[\"clean_text\"].map(' '.join), \n",
    "      data[\"label\"], test_size = 0.2, random_state = 42) # 20% of the data for testing the model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "# normal distribution is not assumed by random forest, but we apply transfromation to transform \n",
    "# textual data(categorical data) into numeriacl.\n",
    "# alternatively we can apply one-hot encoding for the same purpose.\n",
    "# l2: Sum of squares of vector elements is 1 # apply sublinear Tf scaling\n",
    "transformer = TfidfTransformer(norm='l2',sublinear_tf=True)\n",
    "x_train_features = count_vect.fit_transform(x_train)\n",
    "x_train_norm = transformer.fit_transform(x_train_features)\n",
    "#print(x_train_features.shape)\n",
    "print(x_train_norm.shape)\n",
    "\n",
    "#Output :(130378, 84916) \n",
    "x_test_features = count_vect.transform(x_test)\n",
    "x_test_norm = transformer.transform(x_test_features)\n",
    "print(x_test_features.shape)\n",
    "print(x_test_norm.shape)\n",
    "#Output :(32595, 84916)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c81e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification model; RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,f1_score, accuracy_score  \n",
    "# the No. of trees in the model,\n",
    "# n_jobs to run the algorithm in parallel(fit, predict, decision_path and apply are all parallelized over the trees),\n",
    "# -1 to use all processors\n",
    "# criterion:  used to measure the quality of a split\n",
    "RF_model = RandomForestClassifier(n_estimators=350, criterion='gini', n_jobs= -1)  \n",
    "RF_model.fit(x_train_norm, y_train)\n",
    "predictions = RF_model.predict(x_test_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-score is a measure of a test's accuracy. Used to compare the performance of two classifiers.\n",
    "# If average= None, the scores for each class are returned.\n",
    "f1score= f1_score(y_test,predictions, average = None)\n",
    "print('f1_score:',f1score )\n",
    "\n",
    "#Accuracy_score\n",
    "acc_score = accuracy_score(y_test,predictions)*100\n",
    "print('accuracy score:',acc_score)\n",
    "\n",
    "# model evaluation using Confusion Matrix \n",
    "CM = confusion_matrix(y_test,predictions)\n",
    "print('confusion_matrix:\\n', CM) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying Naive Bayes classification MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_model = MultinomialNB()\n",
    "#fitting NB classifier, we use monogram tokenizer; tokenizing each word as one token\n",
    "NB_model.fit(x_train_features, y_train)\n",
    "\n",
    "# NB classifier evaluation\n",
    "from sklearn import metrics\n",
    "predictions= NB_model.predict(x_test_features)\n",
    "metrics.accuracy_score(predictions, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee375da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
