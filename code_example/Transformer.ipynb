{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4315477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing transformer library\n",
    "!pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a3c8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42997    TP-Link TL-UE300 USB 3.0 to RJ45 Gigabit Ether...\n",
      "Name: product_description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# installing dataset\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "data = pd.read_csv(\"ecomm_data.csv\")\n",
    "# remaove na values\n",
    "data = data.dropna()\n",
    "# shuffle data\n",
    "data = shuffle(data)\n",
    "# rename column names using col index\n",
    "data.rename(columns={data.columns[0]: \"label\", data.columns[1]: \"product_description\"}, inplace=True)\n",
    "print(data.head(1)['product_description'])\n",
    "\n",
    "# replace catecorical with numerical values\n",
    "data['label'].replace([ \"Electronics\",  \"Household\", \"Books\", \"Clothing & Accessories\"],\n",
    "                        [0, 1, 2, 3], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd701833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product_desc': ['TP-Link TL-UE300 USB 3.0 to RJ45 Gigabit Ethernet Network Adapter Style name:UE300   UE300 adds gigabit Ethernet network connectivity to those devices without Ethernet LAN port, such as Ultrabook or MacBook Air, through a USB 3.0 port, also being compatible with USB 2.0 and USB1.1 standard.', 'The Power Of Your Subconscious Mind From the Publisher \"I have seen miracles happen to men and women in all walks of life all over the world.\" -- Dr. Joseph Murphy. At last, a great new scientific discovery brings the incredible force of your subconscious mind under your control. Here are the simple, scientifically proven techniques and the astonishing facts about how your subconscious powers can perform miracles of healing. How lung cancer has been cured and optic nerves made whole again. How you can use the newly discovered Law of Attraction to increase your money-getting powers. How your subconscious mind can win you friends, peace of mind, and even help you to attract the ideal mate. How your dreams can help you solve problems and make difficult decisions -- or warn you of potential disaster. Prosperity, happiness and perfect health are yours when you use The Power Of Your Subconscious Mind. \\t\\t\\t\\t    \\t \\t\\t\\t\\t\\t From the Inside Flap \"I have seen miracles happen to men and women in all walks of life all over the world.\" -- Dr. Joseph Murphy. At last, a great new scientific discovery brings the incredible force of your subconscious mind under your control. Here are the simple, scientifically proven techniques and the astonishing facts about how your subconscious powers can perform miracles of healing. How lung cancer has been cured and optic nerves made whole again. How you can use the newly discovered Law of Attraction to increase your money-getting powers. How your subconscious mind can win you friends, peace of mind, and even help you to attract the ideal mate. How your dreams can help you solve problems and make difficult decisions -- or warn you of potential disaster. Prosperity, happiness and perfect health are yours when you use The Power Of Your Subconscious Mind.'], 'label': [0, 2]}\n",
      "{'product_desc': ['TP-Link TL-UE300 USB 3.0 to RJ45 Gigabit Ethernet Network Adapter Style name:UE300   UE300 adds gigabit Ethernet network connectivity to those devices without Ethernet LAN port, such as Ultrabook or MacBook Air, through a USB 3.0 port, also being compatible with USB 2.0 and USB1.1 standard.', 'The Power Of Your Subconscious Mind From the Publisher \"I have seen miracles happen to men and women in all walks of life all over the world.\" -- Dr. Joseph Murphy. At last, a great new scientific discovery brings the incredible force of your subconscious mind under your control. Here are the simple, scientifically proven techniques and the astonishing facts about how your subconscious powers can perform miracles of healing. How lung cancer has been cured and optic nerves made whole again. How you can use the newly discovered Law of Attraction to increase your money-getting powers. How your subconscious mind can win you friends, peace of mind, and even help you to attract the ideal mate. How your dreams can help you solve problems and make difficult decisions -- or warn you of potential disaster. Prosperity, happiness and perfect health are yours when you use The Power Of Your Subconscious Mind. \\t\\t\\t\\t    \\t \\t\\t\\t\\t\\t From the Inside Flap \"I have seen miracles happen to men and women in all walks of life all over the world.\" -- Dr. Joseph Murphy. At last, a great new scientific discovery brings the incredible force of your subconscious mind under your control. Here are the simple, scientifically proven techniques and the astonishing facts about how your subconscious powers can perform miracles of healing. How lung cancer has been cured and optic nerves made whole again. How you can use the newly discovered Law of Attraction to increase your money-getting powers. How your subconscious mind can win you friends, peace of mind, and even help you to attract the ideal mate. How your dreams can help you solve problems and make difficult decisions -- or warn you of potential disaster. Prosperity, happiness and perfect health are yours when you use The Power Of Your Subconscious Mind.'], 'label': [0, 2]}\n",
      "{'product_desc': ['Maybelline New York Fit Me Matte with Poreless Foundation, 115 Ivory, 30ml Colour:115 Ivory   Its 25% anti-shine perlite + micro blurring powders, make visible pores and shine disappear, getting you the perfect selfie-ready look. 6 shades- Ivory, Medium Beige, Natural Buff, Sun Beige, Toast, Toffee Matte finish foundation.', \"Superman By Kidsville Boys' Sweatshirt Give your little one a new look this winter which will keep them cozy & comfortable with this character printed sweatshirt featuring Superman by kidsville crafted out of 60% cotton 40% poly fleece fabric which keeps warm , this sweatshirt with fleece can be worn anytime for a cool casual look team this with character shorts, joggers or denims\"], 'label': [1, 3]}\n"
     ]
    }
   ],
   "source": [
    "# convert data into dataset\n",
    "df = {'product_desc': data['product_description'], 'label': data['label']}\n",
    "from datasets import Dataset\n",
    "out_df = Dataset.from_dict(df)\n",
    "\n",
    "print(out_df[:2])\n",
    "\n",
    "#load a DistilBERT tokenizer, tokeniztation of the words\n",
    "from transformers import AutoTokenizer\n",
    "# using the distilbert tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", return_tensors='pt')\n",
    "\n",
    "#tokenization function\n",
    "# truncate sequences longer than DistilBERTâ€™s maximum input length\n",
    "\n",
    "def tokenize(data):\n",
    "    return tokenizer(data[\"product_desc\"], truncation=True)\n",
    "\n",
    "#splitting dataset into train and test:\n",
    "train = out_df[:1000]\n",
    "test =  out_df[1000:1100]\n",
    "train = Dataset.from_dict(train)\n",
    "test = Dataset.from_dict(test)\n",
    "\n",
    "\n",
    "print(train[:2])\n",
    "print(test[:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b161bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edc1afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\vocab.txt',\n",
       " 'tokenizer\\\\added_tokens.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c166b6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e9ece439b946859faa2aea4291d087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6023076d538491e999bb46768d8d5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizing train and test sets using map function, to avoid creating tokenizers.Encoding objects and keep dict or Dataset \n",
    "# objects with keys\n",
    "train_tokens = train.map(tokenize, batched=True)\n",
    "test_tokens= test.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c637f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing train and test sets using map function, to avoid creating tokenizers.Encoding objects and keep dict or Dataset \n",
    "# objects with keys\n",
    "train_tokens = train.map(tokenize, batched=True)\n",
    "test_tokens= test.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd50bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to calculate prediction performance of the model:  'accuracy' metric will be used\n",
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "def acc_calculate(pred):\n",
    "    predicted, actual = pred\n",
    "    predicted = np.argmax(predicted, axis=1)# argmax returns indices of the maximum values along axis 1; \n",
    "    # predicted contains the probabilities of all classes for each entry in the dataset,\n",
    "    # the index 0 means that probabilty of class 0 is the highst and so on..\n",
    "    return accuracy.compute(predictions=predicted, references=actual)\n",
    "\n",
    "# create a map of the expected ids to their labels with id2label and label2id:\n",
    "\n",
    "id2label = {0: \"Electronics\", 1: \"Household\", 2: \"Books\", 3:\"Clothing & Accessories\"}\n",
    "label2id = {\"Electronics\": 0, \"Household\": 1, \"Books\":2, \"Clothing & Accessories\":3}\n",
    "\n",
    "## stop here if you are running the code on cpu; this will take around 90 Min. Use the pretraind model below.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191fbb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=4, id2label=id2label, label2id=label2id, from_tf=True\n",
    "#)\n",
    "#model.save_pretrained(\"distilbert_model_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726ae769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# defining the transformer\n",
    "#from_pretrained(): to load the pretrained Bert model weights\n",
    "#AutoModelForSequenceClassification: is a generic sequence classification model that will be instantiated using a pretarined Bert model.\n",
    "\n",
    "transformer = AutoModelForSequenceClassification.from_pretrained(\n",
    "\"distilbert-base-uncased\", num_labels=4, id2label=id2label, label2id=label2id, from_tf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the training parameters\n",
    "training_pars = TrainingArguments(\n",
    "    output_dir=\"my_transformer\",\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True)\n",
    "\n",
    "# defining the trainer of the model\n",
    "#The Trainer class provides an API for feature-complete training in PyTorch\n",
    "trainer = Trainer(\n",
    "    model=transformer,\n",
    "    args=training_pars,\n",
    "    train_dataset= train_tokens,\n",
    "    eval_dataset=test_tokens,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=acc_calculate,\n",
    ")\n",
    "#training the transformer\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066486ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save trainer to a file\n",
    "#trainer.save_model(\"./Distilbert_based_transformer\")\n",
    "\n",
    "# evaluate the model \n",
    "result =trainer.evaluate()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c242a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## resume running the code from here using the saved model..\n",
    "transformer_trained = AutoModelForSequenceClassification.from_pretrained(\"./Distilbert_based_transformer\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5863b1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\la2022\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'Electronics', 'score': 0.9508970975875854},\n",
       "  {'label': 'Household', 'score': 0.017261911183595657},\n",
       "  {'label': 'Books', 'score': 0.017655229195952415},\n",
       "  {'label': 'Clothing & Accessories', 'score': 0.014185710810124874}]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "# This pipeline has a return_all_scores parameter on its __call__ method that allows you to get all scores for each label on a prediction.\n",
    "pipe = TextClassificationPipeline(model=transformer_trained, tokenizer=tokenizer)\n",
    "prediction = pipe(\"NetGen 4k Wi-Fi 16 MP Ultra HD Action Camera\", return_all_scores=True)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GPT-2 to generate text\n",
    "from transformers import pipeline\n",
    "text_generator = pipeline('text-generation', model='gpt2')\n",
    "# generate 5 different sentences by sampling from the top 10 hits:\n",
    "#Temperature is a hyper-parameter used to control the randomness of predictions by scaling the logits before applying softmax.\n",
    "# when temperature is a large value (e.g. 1), the GPT-2 model produces more diversity and also more mistakes and viseversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f49a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_generator.save_pretrained('gpt2_pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84513b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = text_generator(\"in the last few years, a bunch of changes\", do_sample=True, top_k=10, temperature=0.6, max_length=50, num_return_sequences=5)\n",
    "for sent in sentences:\n",
    "  print(sent[\"generated_text\"])\n",
    "  print(\"#\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db78df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
